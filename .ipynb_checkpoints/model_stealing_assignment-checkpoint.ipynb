{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Stealing Attack - Assignment 2\n",
    "\n",
    "**Team Number**: 19 \n",
    "**Task**: Implement a model stealing attack against B4B-protected encoder while minimizing L2 distance\n",
    "\n",
    "## Strategy Overview\n",
    "1. Smart query scheduling to avoid B4B's coverage thresholds\n",
    "2. Noise-adaptive model training\n",
    "3. Embedding space-aware sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import requests\n",
    "import io\n",
    "import base64\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import onnxruntime as ort\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. API Connection Setup\n",
    "\n",
    "Modified to include token and port handling from assignment PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = \"50407833\"  # Replace with token from assignment email\n",
    "PORT = None                # Will be set after API launch\n",
    "SEED = None                # Will be set after API launch\n",
    "\n",
    "def launch_api():\n",
    "    \"\"\"Request new API instance as per assignment instructions\"\"\"\n",
    "    global PORT, SEED\n",
    "    \n",
    "    response = requests.get(\n",
    "        \"http://34.122.51.94:9090/stealing_launch\",\n",
    "        headers={\"token\": TOKEN}\n",
    "    )\n",
    "    answer = response.json()\n",
    "    \n",
    "    if 'detail' in answer:\n",
    "        raise Exception(f\"API launch failed: {answer['detail']}\")\n",
    "    \n",
    "    SEED = str(answer['seed'])\n",
    "    PORT = str(answer['port'])\n",
    "    print(f\"API launched. Seed: {SEED}, Port: {PORT}\")\n",
    "    return SEED, PORT\n",
    "\n",
    "def query_api(images):\n",
    "    \"\"\"Query the victim encoder API with batch of images\"\"\"\n",
    "    endpoint = \"/query\"\n",
    "    url = f\"http://34.122.51.94:{PORT}\" + endpoint\n",
    "    image_data = []\n",
    "    \n",
    "    # Convert images to base64 as required by API\n",
    "    for img in images:\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            img = transforms.ToPILImage()(img)\n",
    "            \n",
    "        img_byte_arr = io.BytesIO()\n",
    "        img.save(img_byte_arr, format='PNG')\n",
    "        img_byte_arr.seek(0)\n",
    "        img_base64 = base64.b64encode(img_byte_arr.getvalue()).decode('utf-8')\n",
    "        image_data.append(img_base64)\n",
    "    \n",
    "    payload = json.dumps(image_data)\n",
    "    response = requests.get(url, files={\"file\": payload}, headers={\"token\": TOKEN})\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"representations\"]\n",
    "    else:\n",
    "        raise Exception(f\"Query failed. Code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Coverage Tracking System\n",
    "\n",
    "Implements local LSH to estimate bucket coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoverageTracker:\n",
    "    def __init__(self, bucket_size=0.15, max_buckets=4096):\n",
    "        self.bucket_map = defaultdict(bool)\n",
    "        self.bucket_size = bucket_size\n",
    "        self.max_buckets = max_buckets\n",
    "        self.query_count = 0\n",
    "        \n",
    "    def _hash_embedding(self, emb):\n",
    "        \"\"\"Simulate LSH bucket assignment\"\"\"\n",
    "        return tuple(np.floor(emb[:5] / self.bucket_size))  # Use first 5 dims\n",
    "        \n",
    "    def update_coverage(self, embeddings):\n",
    "        \"\"\"Update coverage estimate with new embeddings\"\"\"\n",
    "        for emb in embeddings:\n",
    "            self.bucket_map[self._hash_embedding(emb)] = True\n",
    "        self.query_count += len(embeddings)\n",
    "        \n",
    "    def get_coverage(self):\n",
    "        \"\"\"Return current coverage percentage\"\"\"\n",
    "        return len(self.bucket_map) / self.max_buckets\n",
    "    \n",
    "    def is_safe(self, sample_size=1000):\n",
    "        \"\"\"Check if additional queries would be safe\"\"\"\n",
    "        current = len(self.bucket_map)\n",
    "        projected = current + (sample_size * 0.1)  # Estimated new buckets\n",
    "        return projected / self.max_buckets < 0.3  # Stay below 30% coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Processing\n",
    "\n",
    "Modified to use provided ModelStealingPub.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StealingDataset(Dataset):\n",
    "    def __init__(self, data_path=\"ModelStealingPub.pt\"):\n",
    "        original_data = torch.load(data_path)\n",
    "        self.images = original_data.imgs  # PIL Images\n",
    "        self.labels = original_data.labels if hasattr(original_data, 'labels') else None\n",
    "        \n",
    "        # Transformations matching API pre-processing\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(32),\n",
    "            transforms.CenterCrop(32),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        if not isinstance(img, torch.Tensor):\n",
    "            img = self.transform(img)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Architecture\n",
    "\n",
    "Custom architecture designed to match victim's output space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderStealer(nn.Module):\n",
    "    def __init__(self, output_dim=1024):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        \n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, output_dim)\n",
    "        )\n",
    "        \n",
    "        # Noise adaptation module\n",
    "        self.noise_adapter = nn.Sequential(\n",
    "            nn.Linear(output_dim, output_dim//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(output_dim//2, output_dim))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        emb = self.embedding(features)\n",
    "        return emb + 0.1 * self.noise_adapter(emb)  # Learn residual noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Smart Query Strategy\n",
    "\n",
    "Implements coverage-aware sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_strategic_samples(dataset, tracker, batch_size=1000):\n",
    "    \"\"\"Select samples that maximize information while minimizing coverage\"\"\"\n",
    "    # First get low-diversity samples\n",
    "    if tracker.query_count < 5000:\n",
    "        indices = np.random.choice(len(dataset), batch_size)\n",
    "        return [dataset[i] for i in indices]\n",
    "    \n",
    "    # Later use PCA-guided sampling\n",
    "    dummy_embs = np.random.randn(1000, 1024)\n",
    "    pca = PCA(n_components=10).fit(dummy_embs)\n",
    "    \n",
    "    # Select samples that fill empty regions\n",
    "    scores = []\n",
    "    for _ in range(batch_size):\n",
    "        idx = np.random.randint(len(dataset))\n",
    "        img = dataset[idx]\n",
    "        # Simulate embedding with PCA components\n",
    "        fake_emb = np.dot(np.random.randn(10), pca.components_)\n",
    "        bucket = tracker._hash_embedding(fake_emb)\n",
    "        if not tracker.bucket_map.get(bucket, False):\n",
    "            scores.append((idx, 10))  # High priority for empty buckets\n",
    "        else:\n",
    "            scores.append((idx, 1))\n",
    "    \n",
    "    # Select top samples\n",
    "    scores.sort(key=lambda x: -x[1])\n",
    "    return [dataset[idx] for idx, _ in scores[:batch_size]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Loop with Noise Adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, epochs=5):\n",
    "    model.train()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=3e-4)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for images, targets in tqdm(train_loader):\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Main Execution Flow\n",
    "\n",
    "Follows assignment requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Initialize API connection\n",
    "    launch_api()\n",
    "    \n",
    "    # Load dataset\n",
    "    dataset = StealingDataset()\n",
    "    print(f\"Loaded dataset with {len(dataset)} images\")\n",
    "    \n",
    "    # Initialize coverage tracker\n",
    "    tracker = CoverageTracker()\n",
    "    \n",
    "    # Phase 1: Initial queries (low diversity)\n",
    "    print(\"Phase 1: Initial low-diversity queries\")\n",
    "    phase1_images = [dataset[i] for i in np.random.choice(len(dataset), 5000)]\n",
    "    phase1_embs = []\n",
    "    \n",
    "    # Batch queries as per API limits (1000 images per query)\n",
    "    for i in range(0, len(phase1_images), 1000):\n",
    "        batch = phase1_images[i:i+1000]\n",
    "        embs = query_api(batch)\n",
    "        phase1_embs.extend(embs)\n",
    "        tracker.update_coverage(embs)\n",
    "        print(f\"Queries: {tracker.query_count}, Coverage: {tracker.get_coverage():.2%}\")\n",
    "    \n",
    "    # Phase 2: Strategic expansion\n",
    "    print(\"\\nPhase 2: Strategic coverage expansion\")\n",
    "    train_data = list(zip(phase1_images, phase1_embs))\n",
    "    \n",
    "    while tracker.query_count < 100000 and tracker.get_coverage() < 0.3:\n",
    "        # Get smart samples\n",
    "        batch_images = get_strategic_samples(dataset, tracker)\n",
    "        batch_embs = query_api(batch_images)\n",
    "        \n",
    "        # Update tracking\n",
    "        tracker.update_coverage(batch_embs)\n",
    "        train_data.extend(zip(batch_images, batch_embs))\n",
    "        \n",
    "        # Periodic training\n",
    "        if len(train_data) % 5000 == 0:\n",
    "            loader = DataLoader(train_data, batch_size=256, shuffle=True)\n",
    "            model = EncoderStealer().to(device)\n",
    "            train_model(model, loader, epochs=3)\n",
    "            \n",
    "        print(f\"Queries: {tracker.query_count}, Coverage: {tracker.get_coverage():.2%}\")\n",
    "    \n",
    "    # Final training\n",
    "    print(\"\\nFinal training\")\n",
    "    final_loader = DataLoader(train_data, batch_size=256, shuffle=True)\n",
    "    model = EncoderStealer().to(device)\n",
    "    train_model(model, final_loader, epochs=10)\n",
    "    \n",
    "    # Export to ONNX as required\n",
    "    print(\"\\nExporting model to ONNX\")\n",
    "    dummy_input = torch.randn(1, 3, 32, 32).to(device)\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        dummy_input,\n",
    "        \"stolen_model.onnx\",\n",
    "        input_names=[\"x\"],\n",
    "        output_names=[\"output\"],\n",
    "        dynamic_axes={'x': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    "    )\n",
    "    \n",
    "    # Validate ONNX\n",
    "    validate_onnx(\"stolen_model.onnx\")\n",
    "    \n",
    "    # Submit as per assignment\n",
    "    submit_model(\"stolen_model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Submission Helpers\n",
    "\n",
    "Directly from assignment example code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_onnx(model_path):\n",
    "    \"\"\"Validate the exported ONNX model meets requirements\"\"\"\n",
    "    try:\n",
    "        session = ort.InferenceSession(model_path)\n",
    "        input_name = session.get_inputs()[0].name\n",
    "        \n",
    "        # Test with random input\n",
    "        test_input = np.random.randn(1, 3, 32, 32).astype(np.float32)\n",
    "        output = session.run(None, {input_name: test_input})[0]\n",
    "        \n",
    "        # Check output dimensions\n",
    "        assert output.shape == (1, 1024), f\"Invalid output shape: {output.shape}\"\n",
    "        print(\"ONNX validation passed!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"ONNX validation failed: {str(e)}\")\n",
    "\n",
    "def submit_model(model_path):\n",
    "    \"\"\"Submit the model for evaluation\"\"\"\n",
    "    url = \"http://34.122.51.94:9090/stealing\"\n",
    "    \n",
    "    with open(model_path, \"rb\") as f:\n",
    "        files = {\"file\": f}\n",
    "        headers = {\"token\": TOKEN, \"seed\": SEED}\n",
    "        response = requests.post(url, files=files, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(\"Submission successful!\")\n",
    "        print(response.json())\n",
    "    else:\n",
    "        print(f\"Submission failed: {response.status_code}\")\n",
    "        print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Run the Attack\n",
    "\n",
    "Execute the complete pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
